\section{Introduction}

The problem with modern research trends (Google Pagerank, Netflix
prize, etc) is that we're pursuing human ideas of ``good''.
There is no gold standard, no way to prove correctness except
by example and rhetoric.
This research has the same problem, though we've tried to address
that by having human evaluations and other measures.

The problem of evaluation is also a matter of quality, or at least
putting a quantity on the quality.
In our original work, we propose several ways to do evaluation.
Vandalism includes several different kinds of evaluation.
Problem in our field is that nearly no one does head-to-head
comparisons, so it's legitimate to post some precision/recall
numbers that ``look good'' and then be done with it.

Working in industry, evaluation is also the first thing tossed
out the window in the rush to file patents or create demos.

