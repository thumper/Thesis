\section{Conclusions}

The problem of tracking text authorship across multiple revisions
is not well-studied.
We have proposed several criteria to define preferable matches,
but other possible formulations
might be equally valid.

A significant problem in defining the criteria for a
good solution to tracking authorship is the handling of short matches.
For example, consider the two-word match ``of the''; describing
it as a two-word match immediately rules out three- and four-word
matches that include the adjacent words.
Most people would describe the two words as completely
unoriginal (to be discarded via a stop-word list~\cite{Kinzler2011},
or possibly always to be part of some larger phrase),
so that a match so small should always be discarded.
Incorporating the $n$-gram frequency into the match quality
score would be one way to avoid giving away credit for phrases
commonly used as a unit in the language.

Now consider the case of a larger $n$-gram: suppose there is a match
of the phrase ``the President of the United States'' between a new
revision and some older revision.
We have just suggested that statistically improbable phrases are
good candidates for ascribing authorship to the first person to
introduce the phrase into an article.
For example, in an article about Caltech, the first person to
add text describing a commencement speech by ``former President of
the United States, Bill Clinton'' should certainly get credit for
any appearance of the phrase ``President of the United States''
in later revisions.
What about when this phrase appears in an article titled
``President of the United States?''
If we apply the same rule, the first person to introduce the phrase
might receive much credit if the phrase is used many times throughout
the article.
Clearly, there is some threshold frequency within a single
article where a phrase is no longer \textit{original}.

The challenge illustrated by these two issues is that the notion
of authorship really revolves around both ideas and specific
words reflecting those ideas.
Until natural language understanding makes more progress, this seems
like a problem that heuristics will have to address
(\eg as is done in tf-idf~\cite{Jones1972}).
How does one compare two different text tracking algorithms?
How would we discover other cases that demonstrate where our
specifications of the solution are incomplete?
These are open problems outside the scope of this work.

Our own work has chosen to favor a faster implementation, and
in this chapter we have presented some basic algorithms to solve text
differencing and author tracking in the context of an edit history.
After including several optimizations, we have achieved run times
of about a week to process several years of article history for
the English Wikiedia.

