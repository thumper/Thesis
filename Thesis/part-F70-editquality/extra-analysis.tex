\section{Additional Analysis}

The results presented in the last section raised two
additional questions.
In comparison to edit longevity, the performance of ${\approx}29.26\%$
PR-AUC is quite poor; why does text longevity not do so well as edit
longevity?
Our second question is about the triangle inequality:
how important is it that our edit distance function satisfy
this property to be a good predictor of vandalism?

\subsection{Edit Longevity Outperforms Text Longevity}

As part of our investigation, we started looking at specific
instances of text longevity values.
In Figure~\ref{fig:ts-GWB-SCBB},
we see the text survival for two different contributions;
both do seem to have the general ``exponential'' shape
that we previously described.
Also computed in each figure is the text longevity measure based on
the 20~revisions shown in each graph, but notice that the text
longevity computed for
Figure~\ref{fig:ts-GeorgeWBush} doesn't exhibit the curve we expect.

\begin{figure}[tbph]
\centering
\subfloat
  [Text survival for article \textit{George W.~Bush}]
  [The text survival graph for the text contributed early
    in the history of article \textit{George W.~Bush}.]
  {
    \framebox{\includegraphics[width=0.45\textwidth]{part-F70-editquality/graph-TS-GeorgeWBush-8574490}}
    \label{fig:ts-GeorgeWBush}
  }
\hspace{1ex}
\subfloat
  [Text survival for article \textit{Santa Cruz Beach Boardwalk}]
  [The text survival graph for the text initially contributed
	as part of the article \textit{Santa Cruz Beach Boardwalk}.]
  {
    \framebox{\includegraphics[width=0.45\textwidth]{part-F70-editquality/graph-TS-SantaCruzBeachBoardwalk}}
    \label{fig:ts-SantaCruzBeachBoardwalk}
  }
\caption{
  The text survival quality of two different articles, computed
  based on 20~revisions.
  The majority of the editing happens in the
  revisions immediately after the initial edit, in these two cases.
  \label{fig:ts-GWB-SCBB}
}
\end{figure}

The explanation for this discrepancy turns out to be a flaw in our
thinking about the original model.
While the text survival for contributions does seem to have an
exponential look to it, exponentials do not approach some fixed
non-zero value --- they approach zero.
In order to fit the curve we are describing, the last value
(in the case of the data shown in Figure~\ref{fig:ts-GeorgeWBush},
the amount of text that survives after the $20^{th}$ revision)
should be taken as the ``zero reference point'' which is subtracted
from all the values.
Applying our exponential curve fitting technique to these new values
will give a much better approximation to the data.
The problem with this better fit is that it changes the meaning of
a score of zero; instead of meaning that the text was immediately deleted,
a score of zero would mean that the text immediately reached its
final survival level.
In other words, we would be measuring how quickly the text stabilizes,
rather than how much agreement there was that the text belonged in
the article.


\subsection{The Triangle Inequality}

The intuition behind our formulation of edit longevity relies on
the metaphor analogizing the \intro{distance} between two revisions
with the \intro{work} or \intro{effort} that an author puts
into making the edit from one revision to the other;
in particular, it is the triangle inequality (one of the
metric properties of distance) that allows us to say that we
can compute how much effort was \textit{useful} in bringing
the article closer to how it appears in a future revision.

We have explored the use of several different definitions of
the \intro{edit distance} to represent this distance, but
noted that the triangle inequality did not completely hold;
see~\cite{Sankoff1999} for a summary of known conditions under which
the triangle inequality holds for
\intro{listing}, \intro{alignment}, or \intro{trace} distances.

\begin{figure}[htbp]
\centering
  \subfloat[
    Example of computing listing distance][
    Listing distance is computed by finding the shortest edit script.
    ]{
    \framebox{
      \includegraphics[width=0.4\textwidth]{part-F70-editquality/fig-DiffListing}
    }
  }
  \hspace{2ex}
  \subfloat[
    Example of computing trace distance
    ][
    Simple trace distance is computed by establishing a correspondence
    between the source and target strings, such that trace lines
    do not cross.
    ]{
    \framebox{
      \includegraphics[width=0.4\textwidth]{part-F70-editquality/fig-DiffTrace}
    }
  }
  \\
  \subfloat[
    Example of computing alignment distance
    ][
    Alignment distance is computed by finding an alignment which
    results in the minimum number of insertions and deletions.
    ]{
    \framebox{
      \includegraphics[width=0.4\textwidth]{part-F70-editquality/fig-DiffAlignment}
    }
  }
\caption{
  Examples of the three different methods typically used to compute
  edit distance.  See~\cite{Sankoff1999} for an in-depth discussion
  on the distinctions between these methods.
  \label{fig:trace-alignment-listing}
}
\end{figure}

Our particular difference algorithm makes use of
Tichy's block moves~\cite{Tichy1984}, which amounts to computing
the trace that matches the source string to the target string.
That matches are allowed between any parts of the two strings
is equivalent to allowing transpositions as well as the usual
insert and delete operations; the difference we compute does not support
substitutions of one word with another.
There is previous research on allowing
transpositions~\cite{Lowrance1975,Wagner1975,Sankoff1999} in
computing edit distance; our work primarily differs from this
earlier work in that we prefer to select longest matches rather
than minimizing the total edit distance computed.

The various proposals for edit distance that we investigated are
computations derived from the edit script we compute.
Tichy's original counter-example shows that globally greedy algorithms
such as ours do not compute the minimum edit script
(see Figure~\ref{fig:match-comparison}), making it unlikely that
proposed edit distance formulas guarantee the triangle inequality.

\begin{figure}[htbp]
\centering
  \subfloat[
    Example matching using globally longest match][
    The matching obtained using the WikiTrust method of
      determining all matches and selecting the longest matches first.
    ]{
    \framebox{
      \includegraphics[width=0.4\textwidth]{part-F70-editquality/fig-MatchingGlobal}
    }
  }
  \hspace{2ex}
  \subfloat[
    Example matching using best match in left-to-right scan of target
    ][
    The matching obtained using the Tichy method of scanning
      the target string from left-to-right and selecting
      the longest match found in the source string.
    ]{
    \framebox{
      \includegraphics[width=0.4\textwidth]{part-F70-editquality/fig-MatchingLocal}
    }
  }
\caption{
  An example of how the matching between a source string and target string
  can differ between WikiTrust's greedy preference for the longest match
  anywhere between the two strongs, and Tichy's processing of the
  target string from left-to-right and selecting the longest match
  for the given starting position in the target string.
  This example is based on Tichy's original example demonstrating that
  a globally greedy algorithm does not result in the minimum number of
  operations~\cite{Tichy1984}.
}
\label{fig:match-comparison}
\end{figure}

We present in Appendix~\ref{app:editlong-data} data on the frequency
with which the triangle inequality holds for the various combinations
of difference algorithm and edit distance formula; only formula \textbf{ed2}
never violates the triangle inequality.
The proof that the triangle inequality always holds for \textbf{ed2} is
a straight forward enumeration of the cases of a word appearing in any
of three revisions and the resulting contribution to \textbf{ed2}.
\begin{comment}

ED2

cases:
  word exists in all three, then M contribution is the same.
  work exists in a,b, but not c.  then contributes to M(b), D(c), D(a->c).
  word exists in a,c, but not b.  contributes to D(b),I(c), M(a->c)
  word exists in b,c, but not a.  contributes to I(a),M(c), I(a->c)
  word exists in a. D(b), xc, D(c)
                 b. I(b), D(c), xa->c
                 c. xb, I(c), I(a->c)

ED1

d(a,b) + d(b,c) >= d(a,c)

cases:
  i \in {a, b, c} : all in M, w(i,i) = 0.  TRUE.
  i \in {a, b}.  w(i,i) + w(i,-) >= w(i,-)?
                    0   +   1    >=   1?  TRUE
  i \in {a, c}.  w(i,-) + w(-,i) >= w(i,i)?
                    1   +   1    >=   0?  TRUE
  i \in {b, c}.  w(-,i) + w(i,i) >= w(-,i)?
                    1   +   0    >=   1?  TRUE
  i \in {a}.   w(i,-) + w(-,-)   >= w(i,-)?
                    1   +   0    >=   1?  TRUE
  i \in {b}.   w(-,i) + w(i,-)   >= w(-,-)?
                    1 +   1      >=   0?  TRUE
  i \in {c}    w(-,-) + w(-,i)   >= w(-,i)?
                  0   +    1     >=    1? TRUE

This looks like it works.
Must break down in the first case.  What if a work is in all three,
but it switches from M to I?
That is, what it it looks like
         w(i,i) + w(i,i) >= w(i,-) + w(-,i)
            0   +    0   >=    1   +    1
which isn't true.


\end{comment}



