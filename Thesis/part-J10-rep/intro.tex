\section{Introduction}

An obvious way to build a reputation system would be to build one
modeled on eBay or Amazon's rating system: elicit votes from users
on the quality of a revision or the work of an author.
We had several concerns about this style of system: lack of adoption,
Sybil attacks through puppet votes, block voting by cliques of users, and
disrupting the current user experience of the Wikipedia community.
This led us to the idea of \intro{implicit voting} through
actions already taken by the community as part of their normal activities,
an idea related to \intro{revealed preferences}~\cite{Samuelson1938}.
For example, reading an article and not making an edit to it is
an implicit vote (though perhaps not a strong one)
that the article is of good quality; the more page views an article
has, the more we can believe that there are no errors in it.
We call reputation systems that do not use explicit input
from users, but instead depend on the actual content, \intro{content-driven}.


The simplest idea for a content-driven reputation system would measure
how much text an author contributed.
During the course of our research, however, we realized that there are
two distinct ways that authors contribute to the Wikipedia: by adding
new content, and by revising existing content.
Both are important to consider, since several users will
adopt one contribution style and not the other.
In Chapter~\ref{ch:contrib}, we propose several different ways
to measure the contribution of authors.
Two of those models, \tenrevs and \editlong,
are the foundation of the reputation system analyzed
in this chapter.
There are several constants in our final model, which were assigned
values by optimizing for the heuristic that author reputation at
the time of an edit
should be correlated with the edit longevity of that revision.
We use the quality measures developed in Chapter~\ref{ch:editquality}
to evaluate the performance of our reputation system.

\begin{comment}
We introduce in Chapter~\ref{ch:editquality} the notions of
\intro{text longevity}, which describes how added text survives
into later revisions, and \intro{edit longevity}, which measures
how consistent an edit is with later revisions,
to account for these different methods of contribution.
We use the principle that every future author is
implicitly making an evaluation on the work of past authors:
edits and new text that are preserved with later revisions
are judged ``good'' by the community.
\end{comment}


There are several possible applications of computing a reputation
value for authors (for example, to grant or deny editing rights to
crucial pages~\cite{Blaze1996}); within the WikiTrust project,
we use reputation to drive a trust system for
Wikipedia content~\cite{Adler2008b}.\footnote{This trust coloring
is publicly available through our Firefox plugin:
\url{https://addons.mozilla.org/en-US/firefox/addon/wikitrust/}}
The fact that authors can only comment on other authors by
making contributions themselves discourages users from attacking
each other in an unproductive way, because they risk their own reputation in the process.

