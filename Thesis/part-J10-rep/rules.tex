\section{A Content-Driven Reputation System}

We propose a \intro{content-driven} reputation system in
order to preserve the current user experience of the Wikipedia.
There are two behaviors that we choose to promote as desirable:
contributing text to articles, and editing text.
Adding text to articles is a necessary behavior for the Wikipedia
to acquire new knowledge and continue to expand.
However, adding text is not sufficient to make the Wikipedia a
useful resource --- the text must be edited for formatting and
readability, and vandalism must be removed, so the removal and
rearrangement of text is also very important.

To measure text contributions and the amount of editing performed
by an author, we examine only the revision history of each article
and use a text differencing algorithm to assist in computing these values.
Deriving implicit judgements from the history was an important
challenge in this work, and our reputation system builds upon
the ideas developed in Chapter~\ref{ch:editquality} for judgements.
Thus, the central premise of our analysis is the notion that later
authors of an article are implicitly judging the work of earlier authors.
In order to reduce the negative impact of vandals, we scale the
computed judgement by the reputation of the judge, so that high-reputation
judges have a larger influence on improving the reputation of the
author being judged.
This limits the damage that vandals can cause by creating multiple
anonymous accounts, and has the side-effect that a user must make
positive contributions that outweigh their negative contributions.

\subsection{Text Contributions}

We deem a text contribution to be \textit{useful} to the Wikipedia
if it \textit{survives} over multiple revisions.
That is, if later editors choose to preserve the text, then
implicitly they are voting that the contribution was of good
quality.
We would like to increase the reputation of the author making
the text contribution by an amount relative to the size of their
contribution (thus encouraging larger contributions),
but also factoring in the reputation of the judge so as to reduce
the weight of low-reputation users, who might be vandals.

Formally, for an article, $a \in \articles$,
we consider two versions, $\version{i}, \version{j} \in \versions{a}$,
where $i < j$ so that $A_i = \revauthor{\version{i}}$ is the author we are
adjusting the reputation of, and $A_j = \revauthor{\version{j}}$ is the author
making the implicit judgement, where $A_i \not = A_j$.\footnote{Recall
from the definition of \versions{\article{}} in Chapter~\ref{ch:defs}
that the revisions are \intro{filtered} so that there are no consecutive
revisions by the same author.
Where the same author edits multiple revisions in a row, only the
most recent is kept.}
The amount of text contributed in \version{i} that survives
to \version{j} is then given by \tsurv{a}{i,j}, as defined in
Equation~\ref{eq:tsurv}.
Thus, we propose the following rule:

\begin{regola}
\textbf{(reputation update due to text survival)}
\label{rule-text}
  We update the reputation of \revauthor{\version{i}} by considering
  each of the ten following versions as judges,\footnote{See
  Definition~\ref{def:judges}.}
  $v_j \in \judges{a}{10}{i}$, and update the reputation by the amount:
  \[
    \coeffrep \cdot \coefftext \cdot \frac{\tsurv{a}{i,j}}{\tsurv{a}{i,i}}
    \cdot (\tsurv{a}{i,i})^\lengthexp \cdot \log(1 + \rep(\version{j})),
  \]
  where $j = \revpos{\version{j}}$ is the version position of \version{j}
  in \versions{a} (and consequently, $0 < j - i \le 10$),
  $\coeffrep > 0$, $\coefftext \in [0,1]$, and $\lengthexp \in
  [0,1]$ are parameters, and where $\rep(\version{j})$ is the reputation of
  \revauthor{\version{j}} at the time \version{j} is performed.
\end{regola}

\noindent
In this rule, $\tsurv{a}{i,j} / \tsurv{a}{i,i}$ is the fraction of text
introduced at version \version{i} that is still present in version \version{j};
this is a measure of the ``quality'' of \version{i}.
The quantity $\log(1 + \rep(\version{j}))$ is the ``weight'' of the
reputation of \revauthor{\version{j}},
that is, how much the reputation of \revauthor{\version{j}} lends
credibility to the judgements made by \revauthor{\version{j}}.
In Chapter~\ref{ch:contrib}, we saw that for any measure we investigated,
only a few regular contributors dominate the majority of users by
several orders of magnitude.
We therefore use a logarithmic weight for reputation
to ensure that the feedback coming from new authors is not completely
overridden by the feedback coming from the dominant contributors.
The parameters $\coeffrep$, $\coefftext$ and $\lengthexp$ were
determined experimentally via an optimization process, described
in Section~\ref{sec:rep-eval}.
The parameter $\lengthexp \in [0,1]$ is an exponent that specifies how
to take into account the length of the original contribution: if
$\lengthexp = 1$, then the increment is proportional to the length of
the original contribution; if $\lengthexp = 0$, then the increment
does not depend on the length of the original contribution.
The parameter $\coeffrep$ specifies how much the reputation should
vary in response to an individual feedback.
The parameter $\coefftext$ specifies how much the feedback should
depends on residual text (Rule~\ref{rule-text}) or residual edit
(Rule~\ref{rule-edit}, presented later).

To give feedback on a revision, the rule considers at most 10
successive versions.
This ensures that contributors to early versions of articles do not
accumulate disproportionate amounts of reputation.
We considered basing the limit on time, rather than on the number of
versions, but each Wikipedia article has its own rate of change:
using the number of versions ensures that fast and
slow-changing pages are treated in a similar fashion.

\subsection{Edit Contributions}

Similar to text contributions, we define edit contributions to
be \textit{useful} if they \textit{survive} revision by multiple
later authors.
We use the notion of \intro{edit longevity} defined in
Equation~\ref{eq:esurv} as a guide to the quality judgement
made by \revauthor{\version{j}} of the work by \revauthor{\version{i}}:
\begin{equation*}
\esurv{a}{i,i-1,j} = \frac{\dist{a}{i-1,j} - \dist{a}{i,j}}
                        {\dist{a}{i-1,i}}
\end{equation*}
Intuitively, this formula computes whether the work in going
from version \version{i-1} to version \version{i} brings the
article closer to how the article will look in the future
(as seen from the point of view of version \version{j}).
If the edit distance, $\dist{}{}$,
satisfies the triangular inequality,
then $\esurv{a}{i,i-1,j} \in [-1,1]$; for many choices of $\dist{}{}$,
the triangle inequality is not satisfied, so
we restrict the value of $\esurv{}{}$ to be in the range $[-1,1]$
by fixing the value to the closest endpoint when
it falls outside of the range.
For two consecutive edits \version{i}, \version{i+1},
if \version{i} is completely undone in \version{i+1}
(as is common when \version{i} introduces spam or is some other
kind of vandalism), then $\esurv{a}{i,i-1,i+1} = -1$;
if \version{i+1} entirely preserves the work of \version{i},
then $\esurv{a}{i,i-1,i+1} = +1$.
For more distant edits, $\esurv{a}{i,i-1,j}$ is a measure of how much of the
edit performed for version \version{i}
is undone (value $-1$) or preserved (value $+1$) in version \version{j}.

Note that $\esurv{a}{i,i-1,j} < 0$
only when
$\dist{a}{i-1,i} < \dist{a}{i,j}$,
that is,
when \version{j} is closer to the version \version{i-1}
(the \textit{preceding} version), than to version \version{i}.
In other words, \revauthor{\version{j}}
votes to lower the reputation of \revauthor{\version{i}}
only when the preceding \version{i-1} is more like \version{j}
than \version{i} is.
We use the following rule for updating reputations based on
edit contributions.

\begin{regola}
\textbf{(reputation update due to edit survival)}
\label{rule-edit}
  We update the reputation of \revauthor{\version{i}} by
  using the three following revisions as judges,
  $v_j \in \judges{a}{3}{i}$, to compute the following value:
\begin{equation*}
q = \frac{\slack \cdot \dist{a}{i-1,j} - \dist{a}{i,j}}
                        {\dist{a}{i-1,i}}
\label{eq-edit-long}
\end{equation*}
where $j = \revpos{\version{j}}$.
Since $q$ is undefined when \dist{a}{i-1,i} = 0,
we take that to be a special case where no reputation
should accrue to the author of version \version{i}
(\ie we set $q = 0$ in that case).
We also define a \intro{punishing} function
\begin{equation*}
    p(q) =
        \begin{cases}
            1 & \text{if $q \ge 0$,} \\
            -\coeffpunish & \text{if $q < 0$.} \\
        \end{cases}
\end{equation*}

The reputation of \revauthor{\version{i}} is then increased
according to the following formula:
\begin{equation*}
q \cdot p(q)
  \cdot \coeffrep \cdot (1 - \coefftext) \cdot
        (\dist{a}{i-1,i})^\lengthexp \cdot \log(1 + \rep(\version{j}))
\end{equation*}

  In this rule, $\coeffpunish \geq 1$, $\slack \geq 1$, $\coeffrep > 0$,
  $\coefftext \in [0,1]$, and $\lengthexp \in [0,1]$ are parameters,
  and $\rep(\version{j})$ is the reputation of \revauthor{\version{j}}
  at the time version \version{j} is created.
\end{regola}

We constructed this rule to use a modified form of
Equation~\ref{eq:esurv};
the parameter $\slack > 1$ is used to spare $a_i$ from punishment when
the revision from \version{i-1} to \version{i} is only slightly
counterproductive.
On the other hand, when punishment is incurred, its magnitude is
magnified by the amount $\coeffpunish$, raising the reputation cost of
edits that are later undone.
We see amplifying the punishment as being instrumental
to making the threat a credible one.
Without amplification, a rogue contributor could use the reputation
gained in one part of the Wikipedia to constantly destroy a small set
of articles elsewhere.
Amplification makes this harder to achieve.

The parameters $\slack$ and $\coeffpunish$, as well as $\coeffrep$,
$\coefftext$ and $\lengthexp$, were determined via an optimization
process described in Section~\ref{sec:rep-eval}.

\subsection{Computing Content-Driven Reputation}

We compute the reputation for Wikipedia authors as follows.
We examine all revisions in chronological order, thus simulating the
same order in which they were submitted to the Wikipedia servers.
We initialize the reputations of all authors to the value~0.1;
the reputation of anonymous authors is fixed to~0.1.
We choose a positive initial value to ensure that the weight,
$\log (1+r)$, of an initial reputation, $r = 0.1$, is non-zero, priming
the process of reputation computation.
This choice of initial value is not particularly critical (the
parameter $\coeffrep$ may need to be adjusted for optimal performance,
if this initial value is changed).
As the revisions are processed,we use Rules~\ref{rule-text}
and~\ref{rule-edit} to determine which authors are being
judged by the revision being process,
and update the reputations of those authors accordingly.
When updating reputations, we ensure that they never become negative,
and that they never grow beyond a bound $\coeffmaxrep > 0$.
The bound $\coeffmaxrep$ prevents frequent contributors from
accumulating unbounded amounts of reputation, and becoming essentially
immune to negative feedback.
The value of $\coeffmaxrep$ was once again determined via
optimization techniques, as described in Section~\ref{sec:rep-eval}.

Wikipedia allows users to register and create an {\em author\/}
identity whenever (and as often as) they wish.
As a consequence, we need to make the initial reputation of new authors
very low, close to the minimum possible (in our case,~0).
If we made the initial reputation of new authors any higher,
then authors, after committing revisions that damage their reputation,
would simply re-register as new users to gain the higher value.
An unfortunate side-effect of allowing people to obtain new identities
at will is that we cannot presume that people are innocent until
proven otherwise: we have to assign to newcomers the same reputation
as proven offenders.\footnote{Perhaps a way out of this conundrum
is to use the methods of vandalism detectors (discussed
in Section~\ref{sec:vandalism-related}) to determine an
initial reputation based on other factors about the edit.}
This is a contributing factor to our reputation having low
{\em precision:\/} many authors who have low reputation still perform
very good quality revisions, as they are simply new authors, rather than
proven offenders.
%% We conjecture that content-driven reputation systems for the Wikipedia
%% would have better predictive value if creating a new author identity
%% was not free, either monetarily, or in some other sense.


