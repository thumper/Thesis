\newcommand{\sign}{{{\textrm{sign}}}}

\subsection{Classifier and Features}

Our vandalism detection tool uses the open source machine learning
package Weka~\cite{Weka09} to build and evaluate a prediction model from
our features.
In the original PAN~2010 competition, we used an alternating decision
tree (ADTree) classifier~\cite{Adler2010b} because it performed well and
generates models that are easy to interpret.
As part of our collaboration in combining multiple vandalism detection
systems~\cite{Adler2011a}, we evaluated the performance of the
WikiTrust features\footnote{In addition to the zero-delay features
described in~\cite{Adler2010b}, we added a feature measuring the length
of the article for~\cite{Adler2011a}.}
using a random forest classifier.
For the experiment in this chapter, we use the same features
from~\cite{Adler2010b} and include the author reputation at the time of
each edit as an additional feature.
Anonymous users have no reputation in the WikiTrust system, and receive
a reputation score of zero within the feature set.

As in~\cite{Adler2011a}, we use the random forest algorithm to build our
prediction model and the standard ten-fold cross-validation to evaluate
the predictive ability..
The Weka command line we used was:
%
{\small
\begin{verbatim}
  weka.classifiers.meta.CostSensitiveClassifier
     -cost-matrix "[0.0 1.0; 10.0 0.0]" -S 1
     -W weka.classifiers.trees.ADTree -- -B 20 -E -3
\end{verbatim}
}

We select a set of features based on the information that is readily
available within the pre-existing WikiTrust system, and only those which
are available at the instant an edit is made.
The purpose of our experiment in this work is to answer the question,
``does the WikiTrust reputation computation provide information about
whether an edit is vandalism?''
In order to make that judgement, we use the same features chosen
in~\cite{Adler2010b} and add the WikiTrust reputation score.
The total set of features we used are:
%
\begin{itemize}

\item \textbf{Author reputation [Reputation].}  Author reputation is an
obvious feature to use, since vandalism tends to be performed
predominantly by anonymous or novice users, both of which have
reputation 0 in the system.

\item \textbf{Author is anonymous [Anon].}  In addition to author
reputation, we also considered the fact of whether the author was
anonymous or not.

\item \textbf{Time interval since the previous revision [Logtime\_prev].}
We compute the quantity $\log(1 + t)$, where $t$ is amount of time since
the preceding revision of the same article.

\item \textbf{Hour of day when revision was created [Hour\_of\_day].}
We expect that the time of day at which the revision was created
might have some influence on the frequency of vandalism.
This did not have much influence in our previous work~\cite{Adler2010b},
but a more sophisticated version proved to contain much
information~\cite{West2010}.

\item \textbf{Delta [Delta].}
This feature measures the edit distance $d(r, r^{-})$ between the
revision and the previous revision in the same article.

\item \textbf{Revision comment length [Comment\_len].}
The length of the comment attached to the revision.

\item \textbf{Previous text trust histogram [P\_prev\_hist0 \ldots P\_prev\_hist9].}
Whenever a revision is created, WikiTrust computes the {\em
reputation\/} of each word of the revision, where the reputation is an
integer in the interval $0, \ldots, 9$~\cite{Adler2008b}.  The
reputation of a word indicates how well the word has been revised by
reputable authors; in particular, words that have been just entered or
displaced by authors without reputation (including both novice and
anonymous authors) are assigned a reputation of~0.  When the revision is
created, WikiTrust also computes a 10-column histogram detailing how
many words of the revision have each of the 10 possible reputation
values, and stores the histogram in the database, in an entry associated
with the revision.  We renormalized the histogram, so that the columns
summed to~1, and we used the renormalized value of each column as a
feature.

\item \textbf{Current text trust histogram [Hist0 \ldots Hist9].}
The current value of the text trust histogram was also provided as a
feature, in this case without any renormalization.

\item \textbf{Histogram difference [L\_delta\_hist0 \ldots L\_delta\_hist9].}
For each possible text trust value $i \in \{0, \ldots, 9\}$, we also
included a measure of $\log(1 + |h(i) - h^{-}(i)|) \cdot \sign(h(i) -
h^{-}(i))$, where $h$ is the text trust histogram for the current
revision, and $h^{-}$ is the text trust histogram for the previous
revision.

\end{itemize}
%

