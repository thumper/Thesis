
\chapter{Vandalism Detection}

Multiple studies have found that roughly 7\% of edits are
vandalism~\cite{Potthast2008,Potthast2010} \mynote{I think
that Luca cites another}.
Due to the preservation of the entire revision history,
anyone can revert an edit, and a group of volunteers scans the
list of recent changes to catch vandalism
quickly~\cite{wiki:RCPatrol}.


\input{part-Q10-vandalism/related-work}



    \section{Features}
        Is it possible to visualize the amount of information
        contained in each feature?
        Has previous work always been a blend of metadata, NLP,
        and reputation?
    \section{Edits}
        Which edits did we guess correctly, where others didn't?
        Why did we guess correctly?  Was it because they were edits
        by old users?

    \section{Future Work}
        Ultimately, Druck~\etal are right when they proclaim that
        vandalism detection must look at the content of the
        edit~\cite{Druck2008}.
        Although metadata methods for identifying bad edits are
        fairly capable, they can always be fooled by a sufficiently
        motivated vandal.
        Vandalism detection will eventually incorporate better
        language models such as those used at Google,
        and will also have specialized topic models (someone did
        something like this!  and compression techniques are
        related).


