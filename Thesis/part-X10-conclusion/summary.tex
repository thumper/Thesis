\section{Summary of this Work}

The creation of a collaborative repository of knowledge is
one of those inevitable ideas; we have been striving towards it
for all of civilization.
Our history is one of ever increasing communication and collaboration
in our ambition to master our environment, from books and libraries
to the telephone and the Internet.
The Wikipedia seems a natural result of this history.
And perhaps just as inevitably, there are people who seek to
mar the collective goals of the Wikipedia for their own gain and amusement.

The goal of our research was to develop a reputation system
that could assist users by flagging content added by users who
did not have a good track record, making the task of understanding
the short-term history of an article easier to grasp with a glance.
In working towards that goal, this research makes the following contributions:
\begin{enumerate}

\item An algorithm for determining the ``authorship'' of words in
  revisioned documents.\footnote{This work is being explored further
  by the German chapter of the Wikipedia: \\
  \url{http://de.wikipedia.org/wiki/Benutzer:NetAction/WikiTrust}}
  This algorithm is a refinement of existing difference algorithms
  already well-known in the literature.

\item Two methods for determining the ``quality'' of a contribution.
  We evaluate these methods (and the underlying difference algorithms)
  using the PAN~2010 vandalism detection corpus, and find that both
  measures perform much better than a random vandalism detector.
  Our \intro{text longevity} measure uses authorship information to
  compute the amount of contributed text and how it survives over
  future revisions (it's ``rate of decay'').
  Our \intro{edit longevity} measure uses edit distances to estimate
  how much ``work'' of an edit goes to making an article more like a
  future instance of the article.
  Edit longevity performs very competitively
  compared to the vandalism detectors participating in the
  PAN~2010 competition~\cite{Potthast2010b}, with the constraint that
  edit longevity uses information ``from the future'' of an edit,
  which was not available to entrants of the competition.

\item A reputation system for authors and text,\footnote{A visualization
  tool is available to users as a Firefox plugin: \\
  \url{https://addons.mozilla.org/en-US/firefox/addon/wikitrust/}}
  which adjusts the reputation of an author based on quality feedback
  from later authors using the ideas of text and edit longevity.
  Our evaluation shows that content by low-reputation authors is
  four times as likely as the average to be short-lived.

\item An evaluation of features from our reputation system
  against the PAN~2010 vandalism detection
  corpus.\footnote{Our features are being utilized by the
  STiki vandalism detection tool~\cite{wiki:STiki}.}

\end{enumerate}

\subsection{Future Work}

A critical part of the training received in graduate school
is the ability to ask questions that creatively expand on your
existing work.
There are a great number of questions left to explore in the
context of WikiTrust, some of which is described here.

\begin{description}
\item[\textbf{category reputation}]
    This is probably the one idea that we hear the most from audiences.
    Everyone has this intuitive understanding that a person can be
    an expert in one area but not another, and that some people don't
    recognize their lack of expertise.
    By keeping track of separate reputation scores for every category,
    the system should be more able to predict the longevity of an edit.
    It is worth noting that, within the Wikipedia community, there
    are those editors which specialize in grammar and style rather than
    subject areas, so that there is some extra work that must go
    into classifying the type of edit (\eg~\cite{Fong2010}).

\item[\textbf{revision selection}]
   In response to the fluid nature of Wikipedia content,
    some users would like to identify versions which
    are ``trustworthy;'' currently, the leading proposal
    for finding these \textit{stable revisions}
    involves manual voting by trusted editors.
    Our own text trust system can highlight text in
    an article which requires greater scrutiny, but
    still requires a diligent user to review previous
    revisions to understand how the article is evolving.
    In a system like WikiTrust, an obvious idea would be to pick
    a recent revision which is least likely to have vandalism.
    An interesting modification to our existing system would be
    to propagate the text trust information we learn from new edits
    back to earlier revisions; in essence, once we know that some
    text is trustworthy, we use that information to reanalyze the
    trust of the revision where it was introduced.

\item[\textbf{match quality}] Our greedy text differencing algorithm
    uses a match quality function to prioritize which matches are
    preferable according to the criteria described in Chapter~\ref{ch:diff}.
    The evaluation in Chapter~\ref{ch:editquality}
    suggests that as long as length
    is the primary discriminant, there is not too much difference
    between the different quality functions.
    The evaluation used is one based on the resulting predictive ability
    of edit quality, but is there some better way to evaluate a difference
    algorithm whose aim is to model the human view of a text edit?

\item[\textbf{reputation as probabilities}]  This view of reputation is
    interesting because interpreting the results becomes clear.
    It also introduces the significant question of how should probabilities
    be adjusted as new information becomes available.
    Owen Martin's work on estimating bug counts provides a nice example:
    you are trying to build a rocketship, and you run many
    tests to try to uncover bugs~\cite{Martin2011}.
    If the test succeeds, your estimate
    of the number of bugs (which is a form of reputation: ``what is
    the probability that the system will fail?'') goes down.
    If the test fails, how do revise your estimate of the number
    of bugs?  And once the engineers have fixed the problem, can
    you be sure they haven't introduced new problems?

\item[\textbf{authorship}]  As described in the concluding remarks of
    Chapter~\ref{ch:diff}, there are further refinements to be
    considered in how to assign authorship in a collaborative work.
    Identifying common idioms in the language (\eg through the use of
    tf-idf~\cite{Jones1972}) and common phrases within a topic area
    are two cases where authorship needs to be more carefully considered.
    The greatest challenge in pursuing this avenue will be in
    determining a suitable evaluation for comparing solutions.

\end{description}

