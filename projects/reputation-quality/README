This directory contains code to evaluate
reputation using the PAN2010
corpus as a golden annotation for "bad edits".

1. Edit parameters in "run-expt.sh" and run as:
    time ./run-expt.sh > expt.out 2>&1 &

  Note that if you're running on a large corpus like enwiki, then I/O will be a
  limiting factor.  Use a RAID-0 array with as many disks as you can.  I used
  8x 1TB disks on Amazon EBS, which performed decently.

  Also note that run-expt.sh is broken down into the separate steps,
  and each step is annotated with whether it can be parallelized or not.
  Use the code in projects/dist-compute to do the parallelization.

2. Double-check that there are no errors in the experiment:
    grep -i trace expt.out
    grep -i error expt.out

2. Extract the reputation scores for the PAN revisions.

    ./extract-repsFrepfile.pl pan2010.csv \
	/mnt/thumper/tmp-rep-enwiki/generate_reputations.vandalrep
	> data/features-reputation.csv

3. Extract other features from SQL files:
    ./extract-dataFsql.pl pan2010.csv \
	/raid/thumper/util/tmp/output-enwiki/sql \
	> features-sqlbased.csv

    (Note that these steps are separate because they take so long
    to run.  Having them separate allows us to rerun any single step.)

   NOTE: Instead of this step, I pulled from our old PAN2010 dataset

4. Combine the reputation scores with the training data

    ./combine-features.pl pan2010.csv.bz2 data/features-reputation.csv.bz2 data/wikitrust-zerodelay.csv.bz2 > data/complete-features.arff

5: Build the RandomForest model and evaluate

    cd expt-part2
    ./classification_experiments.bash

